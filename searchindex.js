Search.setIndex({"docnames": ["about/index", "blog/index", "index", "posts/2021/cnn-architecture-principle", "posts/2021/empirical-mode-decomposition", "posts/2021/logistic-regression", "posts/2021/normalisation-par-lots", "posts/2021/principal-component-analysis", "posts/2022/bert-classification-for-research-papers", "posts/2022/the-transformer-architecture-pytorch"], "filenames": ["about/index.md", "blog/index.md", "index.md", "posts/2021/cnn-architecture-principle.md", "posts/2021/empirical-mode-decomposition.md", "posts/2021/logistic-regression.md", "posts/2021/normalisation-par-lots.md", "posts/2021/principal-component-analysis.md", "posts/2022/bert-classification-for-research-papers.md", "posts/2022/the-transformer-architecture-pytorch.md"], "titles": ["About me", "All Posts", "Godwin Houdji - about me", "Brief introduction to Convolutional Neural Networks", "Empirical Mode Decomposition", "What to know about Logistic Regression ?", "La normalisation par lots", "Principal Component Analysis", "Bert Classification For Research Papers", "Architecture du transformer et impl\u00e9mentation avec Pytorch (Partie I)"], "terms": {"data": [0, 1, 2, 4, 5, 7], "ai": 0, "i": [0, 1, 2, 3, 4, 5, 7], "love": 0, "turn": 0, "intellig": 0, "m": [0, 2, 3, 5], "explor": [0, 2], "how": [0, 1, 2, 3, 5, 8], "languag": [0, 2, 8, 9], "technologi": 0, "can": [0, 2, 4, 5, 7, 8], "drive": [0, 2], "real": [0, 2, 4, 5], "world": [0, 2], "impact": [0, 2], "build": [0, 1, 2, 3], "tool": [0, 1, 2, 4], "make": [0, 1, 2, 5, 8], "tech": 0, "genuin": 0, "us": [0, 1, 2, 3, 4, 5, 7, 8], "from": [0, 2, 3, 4, 5, 8, 9], "natur": [0, 8, 9], "process": [0, 4, 7, 8, 9], "underrepres": 0, "experi": [0, 2], "measur": [0, 2], "digit": 0, "learn": [0, 1, 2, 5, 6, 8, 9], "shape": [0, 5, 9], "livelihood": 0, "practis": 0, "qi": 0, "gong": 0, "enjoi": 0, "new": [0, 7], "thing": 0, "constantli": 0, "test": 0, "alwai": 0, "chase": 0, "better": [0, 8], "idea": 0, "meaning": 0, "collabor": 0, "along": [0, 2], "wai": [0, 2, 5], "see": [0, 2, 3, 8], "my": [0, 2, 3], "orcid": 0, "profil": 0, "list": [0, 2], "n": [0, 1, 2, 3, 4, 5, 6, 7, 9], "beat": 0, "an": [0, 1, 2, 3, 4, 5, 7, 8, 9], "ehg": 0, "signal": [0, 1, 2, 4], "forecast": 0, "method": [0, 1, 2, 4, 5, 8], "labour": 0, "predict": [0, 1, 2, 5, 8], "full": [0, 2], "term": [0, 6], "pregnanc": 0, "2022": [0, 1, 2], "intern": [0, 6], "confer": 0, "electr": 0, "comput": [0, 2, 3, 4, 5, 8], "energi": 0, "icecet": 0, "research": [0, 1, 2], "deep": [0, 1, 2, 5, 6, 7, 8, 9], "model": [0, 1, 2, 5, 9], "labor": 0, "electrohysterogram": 0, "best": [0, 5, 8], "paramet": [0, 5, 8], "select": 0, "": [0, 3, 4, 5, 7, 8, 9], "uterin": 0, "contract": 0, "character": [0, 8], "proceed": 0, "methodolog": 0, "work": [0, 1, 2, 4, 5, 8], "improv": [0, 4, 5], "monitor": [0, 8], "through": [0, 1, 2, 3, 5], "optim": [0, 5, 8], "smart": 0, "access": 0, "mobil": 0, "health": 0, "care": 0, "2021": [0, 1, 2], "paper": [0, 1, 2], "driven": [0, 1, 2, 4], "healthcar": 0, "plan": 0, "26": [1, 2], "mai": [1, 9], "architectur": [1, 2, 8], "du": [1, 2, 6], "transform": [1, 2, 4, 7], "et": [1, 2, 5, 6], "impl\u00e9ment": [1, 2], "avec": [1, 2], "pytorch": [1, 2, 3, 8], "parti": [1, 2], "qu": [1, 2, 6, 9], "est": [1, 2, 9], "ce": [1, 2, 6, 9], "un": [1, 2, 6, 9], "mod\u00e8l": [1, 2, 6, 9], "de": [1, 2, 5, 6, 8], "r\u00e9seau": [1, 2, 6, 9], "neuron": [1, 2, 6, 9], "qui": [1, 2, 6, 9], "apprend": [1, 2, 9], "le": [1, 2, 7, 9], "context": [1, 2, 8, 9], "donc": [1, 2, 9], "sen": [1, 2, 9], "en": [1, 2, 5, 6, 9], "suivant": [1, 2, 6, 9], "relat": [1, 2, 9], "dan": [1, 2, 6, 9], "donn\u00e9": [1, 2, 6, 8, 9], "s\u00e9quentiel": [1, 2, 9], "comm": [1, 2, 9], "mot": [1, 2, 9], "cett": [1, 2, 6, 9], "phrase": [1, 2, 9], "la": [1, 2, 9], "version": [1, 2, 9], "original": [1, 2, 9], "leur": [1, 2, 9], "papier": [1, 2, 9], "attent": [1, 2, 6, 8], "you": [1, 2, 3, 5, 8, 9], "need": [1, 2, 3, 7, 9], "auteur": [1, 2, 6, 9], "d\u00e9finiss": [1, 2, 9], "nouvel": [1, 2, 6, 9], "simpl": [1, 2, 9], "bas\u00e9": [1, 2, 9], "uniqu": [1, 2, 9], "sur": [1, 2, 6, 9], "m\u00e9canism": [1, 2, 9], "d": [1, 2, 3, 4, 6, 7, 9], "exempt\u00e9": [1, 2, 9], "enti\u00e8r": [1, 2, 9], "r\u00e9currenc": [1, 2, 9], "ou": [1, 2, 6], "convolut": [1, 2, 9], "22": [1, 2, 3, 7], "mar": 1, "bert": [1, 2, 9], "classif": [1, 2, 5, 9], "For": [1, 2, 4, 5], "our": [1, 2, 5, 7, 8], "goal": [1, 2, 8], "abstract": [1, 2, 8], "titl": [1, 2, 8], "whether": [1, 2, 8], "reject": [1, 2, 8], "11": [1, 2, 3, 7, 9], "dec": 1, "normalis": [1, 2], "par": [1, 2, 9], "lot": [1, 2, 3, 9], "cet": [1, 2, 6], "articl": [1, 2, 3, 5, 6, 8, 9], "je": [1, 2, 6], "vai": [1, 2, 6], "vou": [1, 2, 6, 9], "parler": [1, 2, 6], "techniqu": [1, 2, 5, 6, 7, 8], "efficac": [1, 2, 6, 9], "pour": [1, 2, 6, 9], "am\u00e9lior": [1, 2, 6], "vo": [1, 2, 6], "rendr": [1, 2, 6], "plu": [1, 2, 6, 9], "puissant": [1, 2, 6], "anglai": [1, 2, 6], "batch": [1, 2, 6, 8, 9], "normal": [1, 2, 5, 6], "nou": [1, 2, 6, 9], "allon": [1, 2, 6, 9], "suivr": [1, 2, 6, 9], "chronologi": [1, 2, 6], "grand": [1, 2, 6, 9], "point": [1, 2, 4, 6, 9], "sont": [1, 2, 9], "17": [1, 2], "aug": 1, "brief": [1, 2], "introduct": [1, 2], "neural": [1, 2, 8], "network": [1, 2, 6], "If": [1, 2, 3, 5], "ar": [1, 2, 3, 5, 7, 8], "read": [1, 2, 3, 8], "thi": [1, 2, 3, 4, 5, 7, 8], "mean": [1, 2, 3, 4, 5, 7, 8], "know": [1, 2, 3, 7], "about": [1, 3, 8], "cnn": [1, 2], "have": [1, 2, 3, 4, 5, 7, 8], "heard": [1, 2, 3], "befor": [1, 2, 3], "But": [1, 2, 3], "why": [1, 2, 3], "should": [1, 2, 3], "what": [1, 2, 3], "am": [1, 2, 3], "offer": [1, 2, 3], "here": [1, 2, 3, 5, 8], "inde": [1, 2, 3, 5], "document": [1, 2, 3, 8], "tutori": [1, 2, 3], "video": [1, 2, 3], "subject": [1, 2, 3], "often": [1, 2, 3, 4], "complex": [1, 2, 3], "mathemat": [1, 2, 3, 5, 8], "notion": [1, 2, 3], "difficult": [1, 2, 3, 8], "understand": [1, 2, 3], "part": [1, 2, 3, 4, 5, 7], "It": [1, 2, 3, 5], "small": [1, 2, 3, 4, 8], "vast": [1, 2, 3], "domain": [1, 2, 3], "same": [1, 2, 3], "time": [1, 2, 3, 4, 5, 7, 9], "onc": [1, 2, 3], "basic": [1, 2, 3], "level": [1, 2, 3], "up": [1, 2, 3, 8, 9], "becom": [1, 2, 3, 8], "rel": [1, 2, 3, 7], "straightforward": [1, 2, 3], "14": [1, 2], "princip": [1, 2], "compon": [1, 2], "analysi": [1, 2, 4, 8], "The": [1, 2, 3, 4, 7, 8], "pca": [1, 2, 7], "dimens": [1, 2, 3, 7, 9], "reduct": [1, 2, 7], "wide": [1, 2, 3, 5, 7], "given": [1, 2, 3, 4, 5, 7, 8], "dataset": [1, 2, 7, 8], "featur": [1, 2, 5, 7], "aim": [1, 2, 3, 7], "k": [1, 2, 3, 7, 9], "so": [1, 2, 5, 7], "retain": [1, 2, 5, 7], "most": [1, 2, 4, 7], "variat": [1, 2, 7], "present": [1, 2, 3, 7], "origin": [1, 2, 4, 7, 8], "variabl": [1, 2, 5, 7], "06": [1, 2], "empir": [1, 2], "mode": [1, 2, 8], "decomposit": [1, 2], "introduc": [1, 2, 3, 4, 8], "hilbert": [1, 2, 4], "huang": [1, 2, 4], "emd": [1, 2], "propel": [1, 2, 4], "analyz": [1, 2, 4, 8], "decompos": [1, 2, 4], "non": [1, 2, 4, 6, 8, 9], "stationari": [1, 2, 4], "linear": [1, 2, 4, 5, 6, 8, 9], "gener": [1, 2, 4, 8], "finit": [1, 2, 4], "number": [1, 2, 4, 5, 7], "frequenc": [1, 2, 4], "amplitud": [1, 2, 4], "modul": [1, 2, 4, 6, 8, 9], "intrins": [1, 2, 4], "function": [1, 2, 3, 4, 8, 9], "imf": [1, 2], "23": [1, 2, 7], "apr": 1, "logist": [1, 2], "regress": [1, 2, 8], "when": [1, 2, 5, 8], "come": [1, 2, 5], "machin": [1, 2, 5, 6], "ml": [1, 2], "task": [1, 2, 5, 8], "which": [1, 2, 5, 8], "compromis": [1, 2, 5], "between": [1, 2, 4, 5], "perform": [1, 2, 5, 8], "result": [1, 2, 4, 5, 8], "we": [1, 2, 3, 4, 5, 7, 8, 9], "ll": [1, 2, 5, 7], "differ": [1, 2, 4, 5, 7], "step": [1, 2, 4, 7, 8], "algorithm": [1, 2, 8], "cours": [1, 2, 5], "explan": [1, 2, 3, 4, 5], "gradient": [1, 2, 5, 6, 8, 9], "descent": [1, 2, 5, 6, 8], "hei": 2, "scienc": [2, 5], "engin": [2, 4], "current": [2, 4, 8], "quantit": 2, "nlp": [2, 9], "design": [2, 8], "chang": [2, 6, 8], "share": 2, "blog": 2, "archiv": 2, "more": [2, 5, 8], "complet": [2, 5], "05": 2, "all": [2, 4, 5, 7, 8, 9], "03": 2, "12": [2, 3, 7, 9], "08": 2, "04": 2, "post": [3, 5, 9], "At": [3, 8], "end": [3, 4, 5, 7, 8], "suggest": [3, 5], "two": [3, 4, 5, 8], "interest": [3, 8], "resourc": 3, "deepen": 3, "broaden": 3, "your": [3, 8], "type": [3, 4, 6], "artifici": 3, "ann": 3, "imag": [3, 4, 6, 9], "recognit": 3, "also": [3, 4], "A": [3, 4, 5, 7, 9], "slide": 3, "matrix": [3, 8], "suppos": 3, "input": [3, 4, 5, 9], "x": [3, 4, 5, 6, 7, 8, 9], "4": [3, 9], "begin": [3, 5, 7], "bmatrix": [3, 7], "b": [3, 4, 5, 7], "c": [3, 4, 7, 9], "e": [3, 4, 5], "f": [3, 4, 6, 7, 8, 9], "g": [3, 5], "h": [3, 4, 5, 9], "j": [3, 5], "l": [3, 6, 8, 9], "o": [3, 8], "p": [3, 5, 8, 9], "To": [3, 5, 7, 8], "oper": [3, 8], "kernel": 3, "size": [3, 8, 9], "refer": 3, "window": 3, "over": 3, "stride": [3, 6], "indic": [3, 8], "mani": 3, "pixel": 3, "shift": [3, 6], "let": [3, 4, 5, 7], "associ": 3, "k_": 3, "21": [3, 7], "follow": [3, 5, 7, 8], "y_": 3, "1": [3, 4, 5, 6, 7, 9], "cdot": 3, "2": [3, 4, 5, 6, 7, 9], "3": [3, 4, 5, 6, 7, 9], "after": [3, 7, 8], "activ": [3, 6, 9], "appli": [3, 9], "interact": [3, 9], "gradual": 3, "decreas": [3, 7], "spatial": 3, "extent": 3, "By": 3, "max": [3, 8], "left": [3, 8], "right": [3, 8], "intention": 3, "out": [3, 8], "etc": [3, 4, 9], "becaus": [3, 4, 5, 7], "below": 3, "talk": 3, "veri": [3, 8], "clearli": 3, "object": [3, 5, 8], "wa": [3, 8], "remov": 3, "specif": [3, 8], "take": [3, 4, 5, 8], "look": 3, "other": [3, 4, 5, 8], "like": [3, 5, 7, 9], "explain": [3, 6, 7, 8], "thank": 3, "t": [4, 5, 7], "sum_": [4, 5, 7], "imf_i": 4, "r": [4, 7], "residuum": 4, "repres": [4, 5, 7], "trend": 4, "compar": 4, "fourier": 4, "wavelet": 4, "must": [4, 5, 8], "satisfi": 4, "main": [4, 5, 8], "condit": [4, 5, 8], "extrema": 4, "equal": [4, 7], "zero": [4, 5], "cross": [4, 5], "instanc": 4, "total": 4, "minima": 4, "50": 4, "maxima": 4, "51": 4, "averag": [4, 5, 8], "envelop": 4, "valu": [4, 5, 7, 8, 9], "describ": [4, 8], "local": 4, "ha": [4, 7, 8], "ex": 4, "0": [4, 5, 6, 7, 8, 9], "taken": 4, "plot": 4, "some": 4, "matlab": 4, "load": 4, "sinusoidalsignalexampledata": 4, "mat": 4, "100": [4, 8], "onli": 4, "get": [4, 5, 8], "first": 4, "element": 4, "length": [4, 8], "interpol": 4, "pchip": 4, "As": 4, "remark": 4, "extract": [4, 9], "contain": 4, "fastest": 4, "oscil": 4, "last": [4, 8], "slowest": 4, "In": [4, 5, 8], "sift": 4, "procedur": 4, "identifi": 4, "determin": 4, "upper": 4, "lower": 4, "them": 4, "subtract": 4, "replac": 4, "calcul": [4, 5, 9], "repeat": 4, "upon": 4, "achiev": 4, "flowchart": [4, 7], "td": 4, "start": [4, 5, 7], "ye": 4, "exampl": [4, 5, 7, 8], "rightarrow": 4, "draw": 4, "locat": 4, "case": [4, 5, 7, 8], "continu": 4, "might": 4, "lost": 4, "dure": 4, "sampl": [4, 7, 8], "depend": [4, 8], "initi": [4, 5, 8], "investig": 4, "made": 4, "order": [4, 5], "known": 4, "ones": [4, 8], "provid": [4, 8], "rill": 4, "biomed": 4, "neurosci": 4, "epidemiologi": 4, "chemistri": 4, "chemic": 4, "financi": 4, "seri": 4, "meteorolog": 4, "atmospher": 4, "solar": 4, "physic": [4, 5], "ocean": 4, "seismic": 4, "studi": 4, "sourc": 4, "wikipedia": 4, "ahmadi": 4, "ekhlasi": 4, "decemb": 4, "pp": 4, "18": 4, "19": 4, "2019": [4, 9], "http": [4, 5, 6, 8], "towardsdatasci": [4, 5], "com": [4, 5, 8], "dummi": 4, "93a93304c541": 4, "www": 4, "mathwork": 4, "help": [4, 5], "ref": 4, "html": [4, 5], "go": [5, 8], "raw": [5, 8], "mainli": 5, "stage": [5, 8], "definit": 5, "develop": 5, "assum": [5, 7], "inform": [5, 8, 9], "incom": 5, "client": 5, "insur": 5, "compani": 5, "base": [5, 8, 9], "he": 5, "receiv": 5, "target": [5, 8], "advertis": 5, "y": [5, 6, 7, 9], "subscrib": 5, "servic": 5, "find": [5, 8], "role": 5, "approxim": 5, "output": [5, 6, 7, 8], "word": [5, 8], "good": 5, "textit": 5, "overset": 5, "text": [5, 6, 7, 8, 9], "longrightarrow": 5, "obviou": 5, "error": 5, "each": [5, 7, 8], "y_i": [5, 7], "less": 5, "close": 5, "big": 5, "x_i": [5, 6, 7], "therefor": 5, "unit": 5, "theta": 5, "frac": [5, 6, 7], "vector": 5, "those": 5, "produc": 5, "minimum": 5, "gd": 5, "iter": [5, 8], "whose": 5, "principl": 5, "quit": 5, "intuit": 5, "would": 5, "ball": 5, "drop": [5, 8], "high": 5, "enough": 5, "bowl": 5, "do": [5, 8], "she": 5, "slope": 5, "ani": 5, "bottom": 5, "formula": 5, "coupl": 5, "theta_0": 5, "theta_1": 5, "until": 5, "converg": [5, 8], "theta_j": 5, "alpha": 5, "partial": 5, "quad": [5, 7], "being": 5, "rate": [5, 6, 8, 9], "speed": [5, 8], "want": [5, 8], "larger": 5, "greater": 5, "probabl": 5, "beyond": [5, 8], "even": [5, 8], "diverg": [5, 9], "opposit": 5, "slow": 5, "down": 5, "train": [5, 6], "lr": [5, 7, 8], "classic": 5, "seen": 5, "binari": 5, "theoret": [5, 8], "could": [5, 7], "5": [5, 9], "geq": 5, "howev": 5, "thu": 5, "respect": [5, 7], "leq": 5, "mid": 5, "abov": 5, "sigmoid": 5, "gompertz": 5, "curv": 5, "distribut": [5, 6], "reduc": [5, 6], "center": 5, "law": 5, "latter": 5, "evolut": 5, "observ": [5, 7], "x_": [5, 6], "i1": 5, "theta_2": 5, "i2": 5, "dot": 5, "theta_m": 5, "im": 5, "decis": 5, "class": [5, 6, 8, 9], "logisticregress": 5, "def": [5, 6, 8, 9], "__init__": [5, 6, 8, 9], "self": [5, 6, 8], "01": 5, "independ": [5, 7, 8], "w": [5, 7], "np": [5, 8], "weight": [5, 9], "set": 5, "bia": 5, "return": [5, 6, 8, 9], "z": 5, "expit": 5, "strongli": 5, "penal": 5, "fals": [5, 8, 9], "posit": 5, "neg": 5, "log": [5, 8], "overal": 5, "code": [5, 8, 9], "write": 5, "entropi": 5, "coss": 5, "python": 5, "implement": 5, "discuss": 5, "gradient_desc": 5, "deriv": 5, "dw": 5, "axi": 5, "dj": 5, "db": 5, "updat": 5, "final": [5, 7, 9], "proce": 5, "fit": [5, 8], "epoch": [5, 8], "100000": 5, "creat": [5, 9], "store": 5, "connect": [5, 9], "line": 5, "bias": 5, "cl": [5, 9], "len": [5, 8], "rang": [5, 8, 9], "flatten": [5, 6, 8], "That": [5, 7], "hope": 5, "found": 5, "question": [5, 9], "aris": 5, "ve": [5, 7], "notic": 5, "mistak": 5, "pleas": [5, 8], "leav": 5, "comment": 5, "issu": 5, "github": [5, 9], "anim": 5, "cheatsheet": 5, "readthedoc": 5, "io": [5, 8], "latest": 5, "logistic_regress": 5, "eric": 5, "biernat": 5, "michel": 5, "lutz": 5, "fondamentaux": 5, "\u00e9tude": 5, "ca": 5, "apprentissag": [6, 9], "supervis\u00e9": 6, "fair": 6, "convers": 6, "sorti": [6, 9], "inter": 6, "couch": 6, "autr": [6, 9], "espac": 6, "selon": 6, "ont": [6, 9], "propos\u00e9": 6, "m\u00e9thode": 6, "format": [6, 9], "r\u00e9seaux": [6, 9], "profond": 6, "compliqu\u00e9": 6, "fait": [6, 9], "que": [6, 9], "entr\u00e9": [6, 9], "chaqu": [6, 9], "au": [6, 9], "cour": 6, "fur": 6, "\u00e0": 6, "mesur": [6, 9], "param\u00e8tr": [6, 9], "pr\u00e9c\u00e9dent": 6, "changent": 6, "ainsi": 6, "cela": 6, "ralentit": 6, "n\u00e9cessit": [6, 9], "faibl": 6, "taux": [6, 9], "initialis": 6, "minutieus": 6, "rend": 6, "notoir": 6, "difficil": 6, "entra\u00een": [6, 9], "lin\u00e9arit\u00e9": 6, "saturant": 6, "sa": 6, "fonction": [6, 9], "r\u00e9initialis": 6, "r\u00e9gularis": 6, "ne": [6, 9], "pa": [6, 9], "r\u00e9utilis": 6, "afin": [6, 9], "ell": [6, 9], "soit": [6, 9], "trait\u00e9": [6, 9], "solut": 6, "va": [6, 9], "permettr": [6, 9], "acc\u00e9l\u00e9rer": 6, "processu": [6, 9], "puisqu": 6, "garantit": 6, "il": [6, 9], "valeur": [6, 9], "trop": 6, "\u00e9lev\u00e9": 6, "tout": [6, 9], "permett": 6, "apprendr": [6, 9], "ind\u00e9pendam": [6, 9], "r\u00e9duir": 6, "pert": 6, "consid\u00e9rabl": 6, "pr\u00e9cision": 6, "ensembl": [6, 9], "diminu": 6, "import": [6, 8, 9], "poid": [6, 9], "initiaux": 6, "permet": [6, 9], "utilis": [6, 9], "beaucoup": [6, 9], "moin": 6, "pui": [6, 9], "stabilit\u00e9": 6, "tel": 6, "leitmotiv": 6, "mise": [6, 9], "\u00e9chell": [6, 9], "formul": 6, "norm": 6, "mu": 6, "sigma": 6, "moyenn": [6, 9], "\u00e9cart": 6, "op\u00e9rat": 6, "invers": 6, "retour": 6, "aux": [6, 9], "initial": 6, "avant": 6, "possibl": [6, 8, 9], "conduit": 6, "accru": 6, "modifi": 6, "tou": [6, 9], "pertin": 6, "faison": 6, "appel": [6, 9], "apr\u00e8": [6, 9], "utilison": 6, "entrain": 6, "reconnaiss": [6, 9], "net": 6, "nn": [6, 8, 9], "super": [6, 8, 9], "conv1": 6, "conv2d": 6, "in_channel": 6, "out_channel": 6, "32": [6, 7], "kernel_s": 6, "bn1": 6, "batchnorm2d": 6, "conv2": 6, "64": [6, 9], "bn2": 6, "premi\u00e8r": [6, 9], "dropout1": 6, "dropout": [6, 8, 9], "25": 6, "fc1": [6, 8], "9216": 6, "128": 6, "fc1_bn": 6, "batchnorm1d": 6, "second": [6, 9], "fc_2": 6, "10": [6, 8], "forward": [6, 8], "relu": [6, 8], "max_pool2d": 6, "torch": [6, 8, 9], "log_softmax": 6, "dim": [6, 8, 9], "sergei": 6, "ioff": 6, "al": [6, 9], "acceler": [6, 8], "covari": 6, "deepai": 6, "org": 6, "glossari": 6, "thankss": 6, "f1": 7, "f2": 7, "f3": 7, "a1": 7, "b1": 7, "c1": 7, "y1": 7, "a2": 7, "b2": 7, "c2": 7, "y2": 7, "a3": 7, "b3": 7, "c3": 7, "y3": 7, "a_i": 7, "b_i": 7, "c_i": 7, "numer": [7, 8], "previou": 7, "written": 7, "a_1": 7, "b_1": 7, "c_1": 7, "a_2": 7, "b_2": 7, "c_2": 7, "a_3": 7, "b_3": 7, "c_3": 7, "row": 7, "column": 7, "hat": 7, "_i": 7, "f_i": 7, "now": [7, 9], "mathrm": 7, "cov": 7, "rule": 7, "rewrit": 7, "_": [7, 8, 9], "f_1": 7, "f_2": 7, "f_3": 7, "note": 7, "diagon": 7, "varianc": [7, 9], "mathbf": 7, "x_1": 7, "x_2": 7, "rise": 7, "too": 7, "mathbb": 7, "squar": 7, "Then": 7, "lambda": 7, "correspond": 7, "equat": 7, "root": 7, "characterist": [7, 8], "det": 7, "ident": 7, "resolv": 7, "sarru": 7, "solv": 7, "got": 7, "lambda_1": 7, "lambda_2": 7, "lambda_3": 7, "tag": 7, "lead": 7, "u": 7, "three": 7, "v": [7, 9], "_1": 7, "v_": 7, "13": 7, "_2": 7, "_3": 7, "31": 7, "33": 7, "choos": 7, "assumpt": 7, "v1": 7, "v2": 7, "dimension": 7, "just": [7, 9], "onto": 7, "subspac": 7, "via": [7, 8], "And": 7, "done": 7, "refin": 8, "accept": 8, "scientif": 8, "huggingfac": [8, 9], "own": 8, "combin": [8, 9], "classifi": [8, 9], "save": 8, "item": 8, "reus": 8, "next": 8, "project": [8, 9], "2018": 8, "bidirect": 8, "encod": [8, 9], "represent": 8, "accord": 8, "its": 8, "author": 8, "unlabel": 8, "togeth": 8, "layer": 8, "aros": 8, "complement": 8, "embed": 8, "elmo": 8, "gpt": 8, "while": 8, "bidirection": 8, "summar": 8, "sensit": 8, "bi": 8, "direct": 8, "agnost": 8, "framework": 8, "lightn": 8, "address": 8, "numpi": 8, "panda": 8, "pd": 8, "request": 8, "dataset_url": 8, "githubusercont": 8, "godwinh19": 8, "iclr": 8, "20paper": 8, "20dataset": 8, "csv": 8, "content": 8, "read_csv": 8, "stringio": 8, "decod": [8, 9], "utf": 8, "8": 8, "usecol": 8, "affichon": 8, "ent\u00eat": [8, 9], "nos": 8, "head": 8, "matter": 8, "On": 8, "polici": 8, "actor": 8, "critic": 8, "recent": 8, "year": 8, "reinforc": 8, "rl": 8, "reach": 8, "supervis": 8, "symbol": 8, "recov": 8, "express": 8, "discov": 8, "underli": 8, "stochast": 8, "tabl": 8, "field": 8, "been": 8, "singl": 8, "call": 8, "descript": 8, "renam": 8, "label": 8, "transformed_data": 8, "copi": 8, "messi": 8, "maintain": 8, "ideal": 8, "decoupl": 8, "readabl": 8, "modular": 8, "doc": 8, "With": 8, "util": 8, "papersdataset": 8, "token": [8, 9], "max_length": 8, "__len__": 8, "__getitem__": 8, "str": 8, "encode_plu": 8, "add_special_token": [8, 9], "true": [8, 9], "return_token_type_id": 8, "pad": 8, "return_attention_mask": 8, "return_tensor": [8, 9], "pt": [8, 9], "truncat": 8, "article_text": 8, "input_id": [8, 9], "attention_mask": 8, "tensor": [8, 9], "dtype": [8, 9], "long": [8, 9], "previous": 8, "simpli": 8, "put": 8, "divid": 8, "larg": 8, "fundament": 8, "requir": 8, "where": 8, "captur": 8, "separ": 8, "later": 8, "still": 8, "neat": 8, "easi": 8, "consist": 8, "detail": 8, "pytorch_lightn": 8, "pl": 8, "berttoken": 8, "sklearn": 8, "model_select": 8, "train_test_split": 8, "bertdatamodul": 8, "lightningdatamodul": 8, "kwarg": 8, "inherit": 8, "bert_pre_trained_model_nam": 8, "uncas": [8, 9], "df_train": 8, "none": 8, "df_val": 8, "df_test": 8, "train_data_load": 8, "val_data_load": 8, "test_data_load": 8, "max_len": 8, "setup": 8, "pars": 8, "split": 8, "valid": 8, "param": 8, "num_sampl": 8, "80": 8, "df": 8, "from_pretrain": [8, 9], "random_se": 8, "random": 8, "seed": 8, "manual_se": 8, "test_siz": 8, "random_st": 8, "stratifi": 8, "create_data_load": 8, "batch_siz": 8, "loader": 8, "datafram": 8, "claim": 8, "datapoint": 8, "construct": 8, "to_numpi": 8, "num_work": 8, "train_dataload": 8, "val_dataload": 8, "test_dataload": 8, "configur": [8, 9], "callback": 8, "earlystop": 8, "modelcheckpoint": 8, "learningratemonitor": 8, "metric": 8, "accuracy_scor": 8, "bertmodel": 8, "adamw": 8, "bertpapersclassifi": 8, "lightningmodul": 8, "schedul": 8, "bert_model": 8, "requires_grad": 8, "n_class": 8, "config": [8, 9], "hidden_s": [8, 9], "512": [8, 9], "attention_mak": 8, "mask": 8, "snippet": 8, "pooler_output": 8, "training_step": 8, "train_batch": 8, "batch_idx": 8, "loss": 8, "devic": 8, "cross_entropi": 8, "test_step": 8, "test_batch": 8, "accuraci": 8, "y_hat": 8, "test_acc": 8, "cpu": 8, "validation_step": 8, "val_batch": 8, "val_step_loss": 8, "validation_epoch_end": 8, "everi": 8, "avg_loss": 8, "stack": 8, "val_loss": 8, "sync_dist": 8, "test_epoch_end": 8, "score": [8, 9], "avg_test_acc": 8, "configure_optim": 8, "001": 8, "lr_schedul": 8, "reducelronplateau": 8, "min": 8, "factor": 8, "patienc": 8, "min_lr": 8, "1e": [8, 9], "6": 8, "verbos": 8, "trainer": 8, "cuda": 8, "empty_cach": 8, "data_modul": 8, "gpu": 8, "b_model": 8, "early_stop": 8, "checkpoint_callback": 8, "dirpath": 8, "getcwd": 8, "save_top_k": 8, "lr_logger": 8, "max_epoch": 8, "datamodul": 8, "state_dict": 8, "bert_model_dict": 8, "6875": 8, "spars": 8, "quantiz": 8, "spectral": 8, "cluster": 8, "sparsifi": 8, "entri": 8, "wise": 8, "nonlinear": 8, "benefit": 8, "core": 8, "algebra": 8, "problem": 8, "filter": 8, "state": [8, 9], "art": 8, "exploit": 8, "theori": [8, 9], "precis": 8, "statement": 8, "eigenspectrum": 8, "under": 8, "particular": 8, "show": 8, "littl": 8, "occur": 8, "eigenstructur": 8, "drastic": 8, "sparsif": 8, "consequ": 8, "downstream": 8, "aggress": 8, "illustr": [8, 9], "phase": 8, "transit": 8, "spuriou": 8, "eigenvector": 8, "load_state_dict": 8, "eval": 8, "unsqueez": [8, 9], "print": 8, "2612": 8, "0729": 8, "grad_fn": [8, 9], "addmmbackward0": 8, "return_typ": 8, "whole": 8, "avail": 8, "french": 8, "increas": 8, "anywai": 8, "product": 8, "cheer": [8, 9], "fig": 9, "applic": 9, "constitu": 9, "mainten": 9, "fondat": 9, "utilis\u00e9": 9, "entr": 9, "t\u00e2che": 9, "r\u00e9pons": 9, "objet": 9, "analys": 9, "sentiment": 9, "l\u00e9gend": 9, "constitu\u00e9": 9, "deux": 9, "encodeur": 9, "d\u00e9codeur": 9, "prend": 9, "s\u00e9quenc": 9, "cr\u00e9e": 9, "repr\u00e9sent": 9, "contextuel": 9, "\u00e9galement": 9, "appel\u00e9": 9, "cell": 9, "ci": 9, "g\u00e9n\u00e8re": 9, "peut": 9, "\u00eatre": 9, "r\u00e9sum\u00e9": 9, "suit": 9, "bloc": 9, "construir": 9, "notr": 9, "propr": 9, "tranform": 9, "commen\u00e7on": 9, "exist": 9, "plusieur": 9, "fa\u00e7on": 9, "mettr": 9, "\u0153uvr": 9, "courant": 9, "produit": 9, "scalair": 9, "tir\u00e9": 9, "pr\u00e9sentant": 9, "quatr": 9, "\u00e9tape": 9, "principal": 9, "n\u00e9cessair": 9, "jeton": 9, "troi": 9, "vecteur": 9, "kei": 9, "queri": 9, "d\u00e9terminon": 9, "quell": 9, "li\u00e9": 9, "similarit\u00e9": 9, "son": 9, "nom": 9, "indiqu": 9, "calcul\u00e9": 9, "matriciel": 9, "incorpor": 9, "similair": 9, "auront": 9, "tandi": 9, "ceux": 9, "commun": 9, "peu": 9, "chevauch": 9, "r\u00e9sultat": 9, "matric": 9, "correspondant": 9, "peuvent": 9, "g\u00e9n\u00e9ral": 9, "produir": 9, "nombr": 9, "arbitrair": 9, "d\u00e9stabilis": 9, "rem\u00e9dier": 9, "abord": 9, "multipli\u00e9": 9, "facteur": 9, "normalis\u00e9": 9, "aid": 9, "softmax": 9, "assur": 9, "somm": 9, "colonn": 9, "\u00e9gale": 9, "contient": 9, "jour": 9, "int\u00e9grat": 9, "foi": 9, "multiplion": 9, "obtenir": 9, "actualis\u00e9": 9, "premier": 9, "temp": 9, "extrair": 9, "facilit\u00e9": 9, "travailleron": 9, "hyper": 9, "retrouvez": 9, "ici": 9, "autotoken": 9, "model_ckpt": 9, "fli": 9, "arrow": 9, "2051": 9, "10029": 9, "2066": 9, "8612": 9, "avon": 9, "ajout\u00e9": 9, "ignor": 9, "sp\u00e9cial": 9, "sep": 9, "ensuit": 9, "devon": 9, "cr\u00e9er": 9, "dens": 9, "signifi": 9, "null": 9, "z\u00e9ro": 9, "seul": 9, "one": 9, "hot": 9, "autoconfig": 9, "bertconfig": 9, "bertformaskedlm": 9, "attention_probs_dropout_prob": 9, "classifier_dropout": 9, "gradient_checkpoint": 9, "hidden_act": 9, "gelu": 9, "hidden_dropout_prob": 9, "768": 9, "initializer_rang": 9, "02": 9, "intermediate_s": 9, "3072": 9, "layer_norm_ep": 9, "max_position_embed": 9, "model_typ": 9, "num_attention_head": 9, "num_hidden_lay": 9, "pad_token_id": 9, "position_embedding_typ": 9, "absolut": 9, "transformers_vers": 9, "type_vocab_s": 9, "use_cach": 9, "vocab_s": 9, "30522": 9, "token_emb": 9, "inputs_emb": 9, "instant": 9, "remettr": 9, "tard": 9, "encodag": 9, "passer": 9, "cr\u00e9ation": 9, "cl\u00e9": 9, "requ\u00eat": 9, "math": 9, "sqrt": 9, "dim_k": 9, "bmm": 9, "transpos": 9, "divis": 9, "avoir": 9, "durant": 9, "appliquon": 9, "sum": 9, "sumbackward1": 9, "attn_output": 9, "venon": 9, "finir": 9, "simplifi\u00e9": 9, "rappelon": 9, "scaled_dot_product_attent": 9, "pratiqu": 9, "appliqu": 9, "lin\u00e9air": 9, "ind\u00e9pendant": 9, "g\u00e9n\u00e9rer": 9, "projett": 9, "ench\u00e2ssement": 9, "port": 9, "appren": 9, "se": 9, "concentr": 9, "diff\u00e9rent": 9, "aspect": 9, "s\u00e9mantiqu": 9, "av\u00e8r": 9, "avantageux": 9, "dispos": 9, "chacun": 9, "pourquoi": 9, "besoin": 9, "raison": 9, "tendanc": 9, "exempl": 9, "sujet": 9, "verb": 9, "trouv": 9, "adjectif": 9, "proch": 9, "\u00e9vident": 9, "int\u00e9gron": 9, "appris": 9, "partir": 9, "analogi": 9, "vision": 9, "ordinateur": 9, "filtr": 9, "neuronaux": 9, "convolutif": 9, "o\u00f9": 9, "respons": 9, "d\u00e9tection": 9, "visag": 9, "recherch": 9, "roue": 9, "voitur": 9, "attentionhead": 9, "embed_dim": 9, "head_dim": 9, "q": 9, "hidden_st": 9, "choisit": 9, "prenant": 9, "pouvon": 9, "concat\u00e9n": 9, "compl\u00e8t": 9, "multiheadattent": 9, "num_head": 9, "modulelist": 9, "output_linear": 9, "cat": 9, "concaten": 9, "encor": 9, "\u00e9gal": 9, "multihead_attn": 9, "sou": 9, "connect\u00e9": 9, "particularit\u00e9": 9, "lieu": 9, "traiter": 9, "trait": 9, "laquel": 9, "souvent": 9, "r\u00e8gle": 9, "empiriqu": 9, "litt\u00e9ratur": 9, "doit": 9, "sup\u00e9rieur": 9, "taill": 9, "feedforward": 9, "linear_1": 9, "linear_2": 9, "feed_forward": 9, "ff_output": 9, "ingr\u00e9dient": 9, "d\u00e9cision": 9, "rest": 9, "prendr": 9, "savoir": 9, "placer": 9, "connexion": 9, "saut": 9, "ait": 9, "unitair": 9, "passent": 9, "tenseur": 9, "ajout": 9, "option": 9, "effectu\u00e9": 9, "disposit": 9, "d\u00e9licat": 9, "former": 9, "car": 9, "verrez": 9, "concept": 9, "connu": 9, "warm": 9, "progressiv": 9, "augment\u00e9": 9, "petit": 9, "maximal": 9, "pendant": 9, "pr\u00e9": 9, "agit": 9, "trouv\u00e9": 9, "place": 9, "port\u00e9": 9, "tend": 9, "stabl": 9, "g\u00e9n\u00e9ralement": 9, "usag": 9, "\u00e9crire": 9, "transformerencoderlay": 9, "l_norm_1": 9, "layernorm": 9, "l_norm_2": 9, "skip": 9, "encoder_lay": 9, "actuel": 9, "invari": 9, "rapport": 9, "etant": 9, "si": 9, "ordr": 9, "respect\u00e9": 9, "constitut": 9, "cr\u00e9on": 9, "personnalis\u00e9": 9, "hidden": 9, "m\u00eame": 9, "chose": 9, "position_id": 9, "paragraph": 9, "pri": 9, "compt": 9, "veut": 9, "dire": 9, "fix\u00e9": 9, "r\u00e9sultant": 9, "simplement": 9, "token_embed": 9, "position_embed": 9, "layer_norm": 9, "ep": 9, "id": 9, "seq_length": 9, "positions_id": 9, "arang": 9, "embedding_lay": 9, "comprendr": 9, "combinon": 9, "transformerencod": 9, "\u00e9tat": 9, "cach\u00e9": 9, "avantag": 9, "divis\u00e9": 9, "corp": 9, "ind\u00e9pend": 9, "sp\u00e9cifiqu": 9, "\u00e9tant": 9, "pr\u00eat": 9, "ajouton": 9, "sera": 9, "transformerforsequenceclassif": 9, "num_label": 9, "encoder_classifi": 9, "d\u00e9fini": 9, "cat\u00e9gori": 9, "envoy\u00e9": 9, "ver": 9, "passag": 9, "ceci": 9, "marqu": 9, "fin": 9, "notebook": 9, "dispon": 9, "book": 9, "annot": 9, "guillaum": 9, "klein": 9, "jai": 9, "alammar": 9}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"about": [0, 2, 5], "me": [0, 2], "godwin": [0, 2], "houdji": [0, 2], "public": 0, "all": 1, "post": [1, 2], "tag": 1, "archiv": 1, "recent": 2, "brief": 3, "introduct": 3, "convolut": 3, "neural": 3, "network": [3, 8], "cnn": 3, "process": 3, "layer": [3, 9], "pool": 3, "empir": 4, "mode": 4, "decomposit": 4, "definit": [4, 7], "how": 4, "imf": 4, "ar": 4, "obtain": 4, "limit": 4, "standard": 4, "emd": 4, "algorithm": [4, 5], "applic": 4, "refer": [4, 5], "what": [5, 8], "know": 5, "logist": 5, "regress": 5, "ml": 5, "step": 5, "The": [5, 9], "hypothesi": 5, "function": 5, "cost": 5, "minim": 5, "la": 6, "normalis": [6, 9], "par": 6, "lot": 6, "c": 6, "est": 6, "quoi": 6, "quel": 6, "sont": 6, "le": 6, "avantag": 6, "comment": 6, "\u00e7a": 6, "fonctionn": 6, "exempl": 6, "avec": [6, 9], "pytorch": [6, 9], "r\u00e9f\u00e9renc": 6, "princip": 7, "compon": 7, "analysi": 7, "covari": 7, "matrix": 7, "comput": 7, "eigenvalu": 7, "eigenvector": 7, "captur": 7, "bert": 8, "classif": 8, "For": 8, "research": 8, "paper": 8, "i": [8, 9], "tool": 8, "pre": 8, "requisit": 8, "1": 8, "data": 8, "prepar": 8, "load": 8, "2": 8, "transform": [8, 9], "column": 8, "3": 8, "input": 8, "model": 8, "dataload": 8, "build": 8, "4": 8, "train": 8, "5": 8, "test": 8, "endnot": [8, 9], "architectur": 9, "du": 9, "et": 9, "impl\u00e9ment": 9, "parti": 9, "self": 9, "attent": 9, "ou": 9, "auto": 9, "multi": 9, "head": 9, "\u00e0": 9, "t\u00eate": 9, "multipl": 9, "feed": 9, "forward": 9, "couch": 9, "propag": 9, "avant": 9, "de": 9, "posit": 9, "embed": 9, "encastr": 9, "positionnel": 9, "ressourc": 9}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"About me": [[0, "about-me"]], "Godwin Houdji": [[0, "godwin-houdji"]], "Publications": [[0, "publications"]], "All Posts": [[1, "all-posts"]], "Tags": [[1, "tags"]], "Archives": [[1, "archives"]], "Godwin Houdji - about me": [[2, "godwin-houdji-about-me"]], "Recent posts": [[2, "recent-posts"]], "Brief introduction to Convolutional Neural Networks": [[3, "brief-introduction-to-convolutional-neural-networks"]], "Introduction": [[3, "introduction"]], "CNN process": [[3, "cnn-process"]], "Convolution Layer": [[3, "convolution-layer"]], "Pooling": [[3, "pooling"]], "Empirical Mode Decomposition": [[4, "empirical-mode-decomposition"]], "Definition": [[4, "definition"], [7, "definition"]], "How IMFs are obtained?": [[4, "how-imfs-are-obtained"]], "Limitations of Standard EMD algorithm": [[4, "limitations-of-standard-emd-algorithm"]], "Applications": [[4, "applications"]], "References": [[4, "references"], [5, "references"]], "What to know about Logistic Regression ?": [[5, "what-to-know-about-logistic-regression"]], "ML algorithms steps": [[5, "ml-algorithms-steps"]], "The hypothesis function": [[5, "the-hypothesis-function"]], "The cost function": [[5, "the-cost-function"], [5, "id1"]], "The minimization of the cost function": [[5, "the-minimization-of-the-cost-function"]], "Logistic Regression": [[5, "logistic-regression"]], "Hypothesis function": [[5, "hypothesis-function"]], "Minimization of cost function": [[5, "minimization-of-cost-function"]], "La normalisation par lots": [[6, "la-normalisation-par-lots"]], "C\u2019est quoi ?": [[6, "c-est-quoi"]], "Quels sont les avantages ?": [[6, "quels-sont-les-avantages"]], "Comment \u00e7a fonctionne ?": [[6, "comment-ca-fonctionne"]], "Exemple avec Pytorch": [[6, "exemple-avec-pytorch"]], "R\u00e9f\u00e9rences": [[6, "references"]], "Principal Component Analysis": [[7, "principal-component-analysis"]], "Covariance matrix": [[7, "covariance-matrix"]], "Compute eigenvalues and eigenvectors": [[7, "compute-eigenvalues-and-eigenvectors"]], "Capture the principal components": [[7, "capture-the-principal-components"]], "Bert Classification For Research Papers": [[8, "bert-classification-for-research-papers"]], "What is BERT?": [[8, "what-is-bert"]], "Tools and pre-requisites": [[8, "tools-and-pre-requisites"]], "1- Data preparation": [[8, "data-preparation"]], "1-1 Loading data": [[8, "loading-data"]], "1-2 Transforming the columns": [[8, "transforming-the-columns"]], "1-3 Transformation of input data to the model": [[8, "transformation-of-input-data-to-the-model"]], "2- Loading data into dataloaders": [[8, "loading-data-into-dataloaders"]], "3- Building the network": [[8, "building-the-network"]], "4- Training": [[8, "training"]], "5- Test": [[8, "test"]], "Endnote": [[8, "endnote"], [9, "endnote"]], "Architecture du transformer et impl\u00e9mentation avec Pytorch (Partie I)": [[9, "architecture-du-transformer-et-implementation-avec-pytorch-partie-i"]], "Self-Attention ou Auto-Attention": [[9, "self-attention-ou-auto-attention"]], "Multi-head attention: attention \u00e0 t\u00eates multiples": [[9, "multi-head-attention-attention-a-tetes-multiples"]], "The Feed-Forward Layer ou couche \u00e0 propagation avant": [[9, "the-feed-forward-layer-ou-couche-a-propagation-avant"]], "Layer Normalisation ou normalisation de couche": [[9, "layer-normalisation-ou-normalisation-de-couche"]], "Positional embeddings ou encastrement positionnels": [[9, "positional-embeddings-ou-encastrement-positionnels"]], "Ressources": [[9, "ressources"]]}, "indexentries": {}})